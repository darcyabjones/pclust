
manifest {
  name = 'pclust'
  description = 'Cluster proteins and annotate them'
  homePage = 'https://github.com/darcyabjones/pclust'
  author = 'Darcy Jones'
  mainScript = 'main.nf'
  nextflowVersion = '>=0.31.1'
  version = "0.0.2"
}

params {
  seqs = false
  db = false
  enrich_db = false
  enrich_seqs = false

  // Options to skip steps, using provided datasets instead
  // Skip the clustering.
  enrich_cluster = false

  clusters = false
  // Skip the multiple sequence alignment.
  msas = false
  // Skip the hhsuite database construction.
  hhself = false

  // Options to stop analyses at points.
  nomsa = false
  tree = false
  noremote_build = false
  noremote = false

  // Remote homology analyses options.
  hhdata = false

  // Provided hhsuite formatted databases to search against.
  // These should be in a directory, and the db name prefix should be 'pfam',
  // 'scop', 'pdb', or 'uniref'.
  // e.g. db/pfam_cs219.ff{data,index} db/pfam_a3m.ff{data,index} etc...
  //
  // I recognise that having to rename things is painful, but there are too many
  // files for each database to provide options for them individually.
  hhpfam = false
  hhscop = false
  hhpdb = false
  hhuniref = false

  // Use these hhblits results instead of running the analyses.
  hhmatches_self = false
  hhmatches_pfam = false
  hhmatches_scop = false
  hhmatches_pdb = false
  hhmatches_uniref = false

  split_size = 20000

  max_memory = 48.GB
  max_cpus = 16
  max_time = 24.h
  help = false
  outdir = "results"
  tracedir = "${params.outdir}/trace"
}


includeConfig "conf/base.config"
process.container = "darcyabjones/${manifest.name}:${manifest.name}-v${manifest.version}"

profiles {
  docker {
    docker.enabled = true
  }
  docker_sudo {
    docker.enabled = true
    docker.sudo = true
  }
  docker_indiv {
    includeConfig "conf/docker_indiv.config"
  }
  singularity {
    singularity.enabled = true
  }
  singularity_indiv {
    includeConfig "conf/singularity_indiv.config"
  }
  pawsey_zeus {
    includeConfig "conf/pawsey_zeus.config"
  }
  nimbus {
    includeConfig "conf/nimbus.config"
  }
}



// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

timeline {
  enabled = true
  file = "${params.tracedir}/pipeline_info/pclust_timeline.html"
}
report {
  enabled = true
  file = "${params.tracedir}/pipeline_info/pclust_report.html"
}
trace {
  enabled = true
  file = "${params.tracedir}/pipeline_info/pclust_trace.txt"
}
dag {
  enabled = true
  file = "${params.tracedir}/pipeline_info/pclust_DAG.svg"
}


// Function to ensure that resource requirements don't go beyond
// a maximum limit
// From NFCORE
def check_max(obj, type) {
  if(type == 'memory'){
    try {
      if(obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
        return params.max_memory as nextflow.util.MemoryUnit
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
      return obj
    }
  } else if(type == 'time'){
    try {
      if(obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
        return params.max_time as nextflow.util.Duration
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
      return obj
    }
  } else if(type == 'cpus'){
    try {
      return Math.min( obj, params.max_cpus as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      return obj
    }
  }
}
